from argparse import ArgumentParser
from collections import defaultdict
from multiprocessing import Pool
from pathlib import Path
from random import choice
from typing import Dict, Tuple

import albumentations as A
import cv2
import imgaug as ia
import numpy as np
from PIL import Image
from tqdm import tqdm

from Cache import cache
from CacheUnclassified import cache as cacheUnclassified


def get_label(name:str, x:int, y:int, n:int):
    global name_to_index
    assert x < n and y < n, f"invalid value x {x} or invalid value y {y}, which suppose to smaller than {n}"
    index = name_to_index[name]
    width = 1 / n
    center = width / 2
    return float(center+width*x), float(center+width*y), float(width), float(width), index

def generate(args:Tuple[Path, int]):
    global CHOICES, IMAGES, LABELS, MODEL, WIDTH, HEIGHT, OBJ_PER_IMAGE, ALBUM, OTHERS
    
    save_path, n = args
    object_count = OBJ_PER_IMAGE if OBJ_PER_IMAGE > 0 else 99999
    object_count = min(object_count, n*n-1)

    default = [i for i in range(n*n)]
    mask = []
    for _ in range(object_count):
        selected = choice(default)
        mask.append(selected)
        default.remove(selected)

    save_image = IMAGES/f"{save_path}.png"
    save_label = LABELS/f"{save_path}.txt"
    images = []
    labels = []
    image_example = choice(MODEL[choice(CHOICES)])

    if OTHERS is None:
        default = np.ones_like(image_example) * 255
    else:
        others_keys = tuple(OTHERS.keys())
    
    with save_label.open("w") as f:
        for y in range(n):
            for x in range(n):
                if int(y*n+x) in mask:
                    image_type = choice(CHOICES)
                    images.append(choice(MODEL[image_type]))
                    labels.append(get_label(image_type, x, y, n))
                    object_count -= 1
                elif OTHERS is None:
                    images.append(default)
                else:
                    images.append(OTHERS[choice(others_keys)])

    image = ia.draw_grid(images, cols=n, rows=n)
    image = cv2.resize(image, (WIDTH, HEIGHT))

    if not ALBUM is None:
        transformed = ALBUM(image=image, bboxes=labels)
        image = transformed['image']
        labels = transformed['bboxes']

    im = Image.fromarray(image)
    im.save(str(save_image))

    with save_label.open("w") as f:
        for x, y, width, height, idx in labels:
            f.write(f"{idx} {x} {y} {width} {height}\n")
            
if __name__ == "__main__":
    parser = ArgumentParser(description="reading images generated by prepare.py and generate images")
    parser.add_argument("-p", "--path", type=str, default="augmented", help="path of images generated by prepare.py")
    parser.add_argument("-t", "--type", type=int, default=[],  help="select image types in number", nargs='+')
    parser.add_argument("--width",      type=int, default=640, help="width of generated image, default 640")
    parser.add_argument("--height",     type=int, default=640, help="height of generated image, default 640")
    parser.add_argument("-n",           type=int, default=2,   help="generate images from 2x2 to nxn")
    parser.add_argument("--objs",           type=int, default=0,   help="objects per image")
    parser.add_argument("-T", "--total-per-type", type=int, default=100, help="numbers for each nxn images")
    parser.add_argument("--save",                           default="yolo", help="directory to save images and lables")
    parser.add_argument("--unclassified", help="insert unclassified images into the blank, all image sizes has to be same as augmented images")
    parser.add_argument("-a", "--album", action="store_true", help="use albumentations")
    args = parser.parse_args()
    
    model = cache(Path(args.path), Path("images.cache"))
    OTHERS = cacheUnclassified(Path(args.unclassified), Path("unclassified.cache")) if args.unclassified else None
    CHOICES = list(model.keys())
    name_to_index:Dict[str, int] = {name:i for i, name in enumerate(CHOICES)}
    assert not args.type or len(CHOICES) >= max(args.type), f"invalid type, you need to choose a number between 0 and {len(CHOICES)} for {CHOICES}"
    
    if args.type and not 0 in args.type:
        CHOICES = [CHOICES[i-1] for i in args.type]
        print("You select image", CHOICES)
    else:
        print("You select all images")

    MODEL = defaultdict(list)
    for image_type in CHOICES:
        for image in model[image_type]:
            MODEL[image_type].append(model[image_type][image])

    # global variable
    N = args.n
    OBJ_PER_IMAGE = args.objs
    WIDTH = args.width
    HEIGHT = args.height
    TOTAL = args.total_per_type
    
    IMAGES = Path(args.save)/"images"
    LABELS = Path(args.save)/"labels"
    IMAGES.mkdir(parents=True, exist_ok=True)
    LABELS.mkdir(exist_ok=True)

    ALBUM = A.Compose([
        A.RandomCrop(width=450, height=450),
        # A.HorizontalFlip(p=0.5),
        # A.RandomBrightnessContras t(p=0.2),
    ], bbox_params=A.BboxParams(format='yolo')) if args.album else None
    
    for n in range(2, N+1):
        images = []
        for i in range(TOTAL):
            save_path = f"{n}-{i:05}"
            if not (IMAGES/f"{save_path}.png").exists():
                images.append((save_path, n))
        if images:
            # for opts in tqdm(images, desc=f"{n}x{n}"):
            #     generate(opts)
            with Pool() as p:
                results = list(tqdm(p.imap_unordered(generate, images), total=len(images), desc=f"{n}x{n}"))
        else:
            print(f"{n}x{n}")